{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3309d966-e118-4022-9cd2-422abcb56bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\n",
    "\n",
    "#ANOVA (Analysis of Variance) assumes:\n",
    "\n",
    "#1. Independence: Observations are randomly sampled and independent of each other.\n",
    "\n",
    "#Violation: Non-independent observations (e.g., repeated measures, clustered data).\n",
    "\n",
    "#1. Normality: Data follows a normal distribution within each group.\n",
    "\n",
    "#Violation: Non-normal data (e.g., skewed, outliers).\n",
    "\n",
    "#1. Homogeneity of variance (Homoscedasticity): Variances are equal across groups.\n",
    "\n",
    "#Violation: Unequal variances (e.g., one group has much larger variance).\n",
    "\n",
    "#1. No significant outliers: No data points are significantly different from the rest.\n",
    "\n",
    "#Violation: Presence of influential outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09a3475b-3366-4d1c-93d9-1b99806a1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "#1. One-way ANOVA:\n",
    "\n",
    "#Used to compare means across three or more independent groups.\n",
    "\n",
    "#Example: Comparing the average scores of students from different schools.\n",
    "\n",
    "#1. Two-way ANOVA:\n",
    "\n",
    "#Used to examine the interaction between two independent variables (factors) on a continuous outcome variable.\n",
    "\n",
    "#Example: Investigating the effect of gender (male/female) and age group (young/old) on cognitive performance.\n",
    "\n",
    "#1. Repeated-measures ANOVA:\n",
    "\n",
    "#Used to compare means across three or more related groups (e.g., same participants measured at different time points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c7bf149-ec54-42cc-871b-05b077476607",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "#1. Between-group variance (SSB): Variance due to differences between group means.\n",
    "#2. Within-group variance (SSW): Variance due to differences within each group.\n",
    "#3. Total variance (SST): Sum of between-group and within-group variance.\n",
    "\n",
    "#Understanding variance partitioning is crucial because:\n",
    "\n",
    "#1. Identifies sources of variation: Helps you understand whether group differences or individual differences contribute more to the total variance.\n",
    "#2. Calculates F-statistic: The ratio of between-group variance to within-group variance is used to calculate the F-statistic, which determines statistical significance.\n",
    "#3. Assesses effect size: Partitioning variance helps estimate the effect size (e.g., eta-squared), which indicates the practical significance of the findings.\n",
    "#4. Informs research decisions: Understanding variance partitioning can guide decisions about future studies, such as identifying factors contributing to variation and optimizing experimental design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0012691-c35a-453d-adec-f805ba97cf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 124.93333333333334\n",
      "SSE: 90.13333333333334\n",
      "SSR: 34.8\n"
     ]
    }
   ],
   "source": [
    "#### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "group1 = np.array([23, 21, 19, 24, 22])\n",
    "group2 = np.array([18, 20, 19, 17, 21])\n",
    "group3 = np.array([25, 24, 23, 26, 27])\n",
    "\n",
    "# Combine data into a single array\n",
    "data = np.concatenate((group1, group2, group3))\n",
    "\n",
    "# Calculate Total Sum of Squares (SST)\n",
    "SST = np.sum((data - np.mean(data))**2)\n",
    "\n",
    "# Calculate Explained Sum of Squares (SSE)\n",
    "group_means = np.array([np.mean(group1), np.mean(group2), np.mean(group3)])\n",
    "SSE = np.sum((group_means - np.mean(data))**2) * len(group1)\n",
    "\n",
    "# Calculate Residual Sum of Squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"SST:\", SST)\n",
    "print(\"SSE:\", SSE)\n",
    "print(\"SSR:\", SSR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52894fc1-1ed4-488a-bfdc-c9d2139ca870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effect of factor A: F-statistic = 12.64, p-value = 0.000\n",
      "Main effect of factor B: F-statistic = 2.44, p-value = 0.135\n",
      "Interaction effect: F-statistic = 12.64, p-value = 0.000\n"
     ]
    }
   ],
   "source": [
    "####Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "\n",
    "#1. Define your data:\n",
    "\n",
    "\n",
    "# Sample data\n",
    "A1B1 = np.array([23, 21, 19, 24, 22])\n",
    "A1B2 = np.array([18, 20, 19, 17, 21])\n",
    "A2B1 = np.array([25, 24, 23, 26, 27])\n",
    "A2B2 = np.array([22, 23, 24, 25, 26])\n",
    "\n",
    "\n",
    "#1. Calculate the main effects:\n",
    "\n",
    "\n",
    "# Main effect of factor A\n",
    "F_A, p_A = f_oneway(A1B1, A1B2, A2B1, A2B2)\n",
    "\n",
    "# Main effect of factor B\n",
    "F_B, p_B = f_oneway(np.concatenate((A1B1, A2B1)), np.concatenate((A1B2, A2B2)))\n",
    "\n",
    "\n",
    "#1. Calculate the interaction effect:\n",
    "\n",
    "\n",
    "# Interaction effect\n",
    "F_AB, p_AB = f_oneway(A1B1, A1B2, A2B1, A2B2)\n",
    "\n",
    "\n",
    "#Note: The f_oneway function from scipy.stats calculates the F-statistic and p-value for a one-way ANOVA. We use it here to calculate the main effects and interaction effect.\n",
    "\n",
    "#1. Print the results:\n",
    "\n",
    "\n",
    "print(\"Main effect of factor A: F-statistic = {:.2f}, p-value = {:.3f}\".format(F_A, p_A))\n",
    "print(\"Main effect of factor B: F-statistic = {:.2f}, p-value = {:.3f}\".format(F_B, p_B))\n",
    "print(\"Interaction effect: F-statistic = {:.2f}, p-value = {:.3f}\".format(F_AB, p_AB))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b541a90-f468-4cd3-b92a-e11c50a8bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.What can you conclude about the differences between the groups, and how would you interpret these results?\n",
    "\n",
    "#1. There is a statistically significant difference between the groups, as the p-value (0.02) is less than the typical significance level (0.05).\n",
    "#2. The null hypothesis is rejected, which means that the assumption of equal means across all groups is not supported by the data.\n",
    "#3. At least one group mean is significantly different from the others, but the F-statistic alone cannot specify which group(s) differ.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f3b5901-aec5-4a97-b1c4-e7cd296b5a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?\n",
    "\n",
    "### In repeated measures ANOVA, missing data can be handled in several ways, each with potential consequences:\n",
    "\n",
    "#1. Listwise deletion: Remove participants with missing data.\n",
    "\n",
    "#Consequence: Reduced sample size, potential bias if missingness is systematic.\n",
    "\n",
    "#1. Pairwise deletion: Remove only the specific data points that are missing.\n",
    "\n",
    "#Consequence: Unequal sample sizes across time points, potential bias if missingness is systematic.\n",
    "\n",
    "#1. Mean imputation: Replace missing values with the mean of the respective time point.\n",
    "\n",
    "#Consequence: Underestimation of variance, potential bias if missingness is systematic.\n",
    "\n",
    "#1. Regression imputation: Use a regression model to predict missing values.\n",
    "\n",
    "#Consequence: Can be effective if missingness is random, but may introduce bias if missingness is systematic.\n",
    "\n",
    "#1. Multiple imputation: Create multiple datasets with different imputed values, analyze each dataset, and combine results.\n",
    "\n",
    "#Consequence: Most robust method, but can be computationally intensive and requires careful implementation.\n",
    "\n",
    "#1. Maximum likelihood estimation: Use statistical software to estimate model parameters, accounting for missing data.\n",
    "\n",
    "#Consequence: Most appropriate method, as it provides unbiased estimates and accurate standard errors.\n",
    "\n",
    "#When handling missing data in repeated measures ANOVA, it's essential to:###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43c2cf54-5f90-41b4-ae27-fa774993c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary.\n",
    " #1. Tukey's HSD (Honestly Significant Difference): Compare all possible pairs of means. Use when you want to conduct multiple comparisons without inflating the Type I error rate.\n",
    "\n",
    "#2. Scheffé's test: Compare all possible contrasts (e.g., pairwise, complex contrasts). Use when you have specific hypotheses about which groups differ.\n",
    "\n",
    "#3. Bonferroni correction: Adjust the alpha level for multiple comparisons. Use when you want to control the family-wise error rate.\n",
    "\n",
    "#4. Dunnett's test: Compare each group to a control group. Use when you have a specific control group and want to compare others to it.\n",
    "\n",
    "#5. Newman-Keuls test: Compare means in a stepwise manner. Use when you want to identify which groups differ without specifying hypotheses.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bdcf85-83ae-49db-9aa0-6ef092cc3d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
